# Kaggle Titanic competition

Competition overview [here](https://www.kaggle.com/c/titanic/overview)

Focusing on applying one new technique at a time, referring to a range of different tutorials to ensure I fully understand what I'm doing at each step as opposed to just trying to maximise my score in the shortest possible time. Building up a learning journal and library of resources as I go.

<table style="margin-left:auto; margin-right:auto">

  <tr>
    <th style="text-align:center">Version</th>
    <th style="text-align:center">Date</th>
    <th style="text-align:center">Score</th>
    <th style="text-align:center">Rank</th>
    <th style="text-align:center">What I did</th>
    <th style="text-align:center">Tutorials referred to</th>
  </tr>

  <tr>
    <td><a href="notebooks/Version_18.ipynb">Version 18</a></td>
    <td>16 Jan 2021</td>
    <td>0.78947</td>
    <td>1364/13444</td>
    <td>
      Hyperparameter optimization using RandomisedSearchCV and GridSearchCV
    </td>
    <td>
      <ul>
        <li><a href="https://www.kaggle.com/mohitsital/random-forest-hyperparameter-tuning">Mohit</a><br></li>
        <li><a href="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74">Will Koehrsen</a><br></li>
      </ul>
    </td>
  </tr>

  <tr>
    <td><a href="notebooks/Version_16.ipynb">Version 16</a></td>
    <td>14 Jan 2021</td>
    <td>0.78468</td>
    <td>no change</td>
    <td>
      Label and one-hot encoding
    </td>
    <td><a href="https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd">Dinesh Yadav</a></td>
  </tr>

  <tr>
    <td><a href="notebooks/Version_15.ipynb">Version 15</a></td>
    <td>14 Jan 2021</td>
    <td>0.78708</td>
    <td>1800/13675</td>
    <td>
      Added new feature 'Title'
    </td>
    <td><a href="https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280">Benedikt Droste</a></td>
  </tr>

  <tr>
    <td><a href="notebooks/Version_12.ipynb">Version 12</a></td>
    <td>13 Jan 2021</td>
    <td>0.78468</td>
    <td>2320/13761</td>
    <td>
      <ul>
        <li>Data cleaning: fill in missing Age, Fare, Embarked, Deck (based on Cabin)</li>
        <li>Binning: Fare, Age</li>
        <li>New feature creation: Family_Size_Bin, Ticket_Freq</li>
      </ul>
    </td>
    <td><a href="https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280">Benedikt Droste</a></td>
  </tr>

  <tr>
    <td><a href="notebooks/Version_1.ipynb">Version 1</a></td>
    <td>7 Jan 2021</td>
    <td>0.77511</td>
    <td>7359/13761</td>
    <td>
      Random Forest model with available features: Pclass, Sex, SibSp, Parch
    </td>
    <td><a href="https://www.kaggle.com/alexisbcook/titanic-tutorial">Alexis Cook</a></td>
  </tr>

</table>          
